{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "ffd80eec819229d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:45:25.461987Z",
     "start_time": "2024-10-29T15:45:17.741589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importiere prozessierte Daten",
   "id": "78b2f54c9c5b56e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:43:58.755700Z",
     "start_time": "2024-10-29T15:43:58.698771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trainings- und Testdaten für lineare Modelle einlesen\n",
    "X_train_lr_pca = pd.read_csv('../data/processed/X_train_lr_pca.csv')\n",
    "X_test_lr_pca = pd.read_csv('../data/processed/X_test_lr_pca.csv')\n",
    "\n",
    "# Trainings- und Testdaten für baumbasierte Modelle einlesen\n",
    "X_train_tree_fs = pd.read_csv('../data/processed/X_train_tree_fs.csv')\n",
    "X_test_tree_fs = pd.read_csv('../data/processed/X_test_tree_fs.csv')\n",
    "\n",
    "# Zielwerte einlesen\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.ravel()\n"
   ],
   "id": "e89b2348a7f0dcaf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:45:41.740219Z",
     "start_time": "2024-10-29T15:45:39.228917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Baseline-Modell: Lineare Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_lr_pca, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_lr_pca)\n",
    "\n",
    "# Evaluierung der Linearen Regression\n",
    "print(\"Lineare Regression - Evaluation:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_lr))\n",
    "print(\"R^2:\", r2_score(y_test, y_pred_lr))\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tree_fs, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_tree_fs)\n",
    "\n",
    "# Evaluierung des Random Forest\n",
    "print(\"\\nRandom Forest - Evaluation:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"R^2:\", r2_score(y_test, y_pred_rf))\n",
    "\n",
    "# 3. Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train_tree_fs, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_tree_fs)\n",
    "\n",
    "# Evaluierung des Gradient Boosting\n",
    "print(\"\\nGradient Boosting - Evaluation:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_gb))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_gb))\n",
    "print(\"R^2:\", r2_score(y_test, y_pred_gb))\n"
   ],
   "id": "e3fe87baf01999df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lineare Regression - Evaluation:\n",
      "MSE: 539.0743880015362\n",
      "MAE: 17.32044943087601\n",
      "R^2: 0.9531002722866916\n",
      "\n",
      "Random Forest - Evaluation:\n",
      "MSE: 135.32947733333333\n",
      "MAE: 3.620177777777778\n",
      "R^2: 0.9882262712163955\n",
      "\n",
      "Gradient Boosting - Evaluation:\n",
      "MSE: 111.38236612938648\n",
      "MAE: 4.546334370460688\n",
      "R^2: 0.990309681261434\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Lineare Regression (Baseline-Modell)\n",
    "- **Mean Squared Error (MSE):** 539.07 – Ein relativ hoher Fehler im Vergleich zu den komplexeren Modellen. Der MSE-Wert gibt an, wie stark die tatsächlichen Werte durchschnittlich vom Modell abweichen. Bei der Linearen Regression ist der MSE deutlich höher, was auf eine geringere Anpassungsfähigkeit hinweist.\n",
    "- **Mean Absolute Error (MAE):** 17.32 – Dieser absolute Fehler zeigt, dass die durchschnittliche Abweichung der Vorhersagen vom tatsächlichen Wert bei etwa 17 liegt.\n",
    "- **R²:** 0.9531 – Die Lineare Regression erklärt etwa 95,3 % der Varianz der Zielvariable. Das Modell zeigt zwar eine hohe Anpassung, wird jedoch durch die einfachere Struktur eingeschränkt.\n",
    "\n",
    "Die Lineare Regression bietet eine solide Grundlage als Baseline, aber die geringere Flexibilität macht es schwieriger, nichtlineare Zusammenhänge genau zu modellieren.\n",
    "\n",
    "## 2. Random Forest\n",
    "- **MSE:** 135.33 – Der Fehler ist im Vergleich zur Linearen Regression deutlich niedriger, was auf eine bessere Anpassung an die Daten hindeutet.\n",
    "- **MAE:** 3.62 – Der absolute Fehler ist ebenfalls deutlich niedriger als bei der Linearen Regression, was auf eine hohe Genauigkeit bei der Vorhersage einzelner Werte hinweist.\n",
    "- **R²:** 0.9882 – Der Random Forest erklärt etwa 98,8 % der Varianz der Zielvariable und erzielt damit eine sehr gute Anpassung.\n",
    "\n",
    "Random Forest passt sich den Daten deutlich besser an und ist in der Lage, komplexere Zusammenhänge zu modellieren. Das Modell zeigt eine hohe Genauigkeit und Stabilität.\n",
    "\n",
    "## 3. Gradient Boosting\n",
    "- **MSE:** 111.38 – Gradient Boosting weist den niedrigsten MSE auf, was darauf hindeutet, dass es die Zielvariable am besten vorhersagt.\n",
    "- **MAE:** 4.55 – Der MAE ist geringfügig höher als beim Random Forest, bleibt jedoch niedrig genug, um die Genauigkeit des Modells zu demonstrieren.\n",
    "- **R²:** 0.9903 – Mit einem R² von 99,0 % erklärt Gradient Boosting den höchsten Anteil der Varianz und passt sich am besten an die Zielvariable an.\n",
    "\n",
    "Gradient Boosting erzielt die besten Ergebnisse in allen Metriken, was auf eine sehr präzise Modellierung der Zielvariable hindeutet. Dies macht es zum besten Modell in diesem Vergleich, da es die Balance zwischen Flexibilität und Genauigkeit am besten erreicht.\n",
    "\n",
    "## Zusammenfassung der Modelle\n",
    "- **Baseline:** Die Lineare Regression bietet eine einfache Vergleichsgrundlage, weist jedoch höhere Fehler auf.\n",
    "- **Random Forest:** Deutlich bessere Anpassung und geringe Fehler; eignet sich gut für komplexe Datenstrukturen.\n",
    "- **Gradient Boosting:** Das leistungsfähigste Modell in diesem Vergleich, mit der besten Vorhersagequalität und der niedrigsten Fehlerrate"
   ],
   "id": "15345fd9daeb7741"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
