{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preparation",
   "id": "70682b6a9a6861f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:40:46.977582Z",
     "start_time": "2024-10-30T15:40:44.610204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ],
   "id": "e1eef165a7028e8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:40:46.997369Z",
     "start_time": "2024-10-30T15:40:46.977582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Laden der Daten\n",
    "# Passe den Pfad entsprechend an, falls die Daten in einem spezifischen Ordner liegen\n",
    "df = pd.read_csv('../data/raw/sickness_table.csv', parse_dates=['date'])"
   ],
   "id": "776cc4fb00d1a906",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:40:47.005273Z",
     "start_time": "2024-10-30T15:40:46.997369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Unnötige Index-Spalte ignorieren\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ],
   "id": "3422d781227689de",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:40:47.015162Z",
     "start_time": "2024-10-30T15:40:47.005273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trenne die Zielvariable vom Feature-Set\n",
    "X = df.drop(columns=['sby_need'])\n",
    "y = df['sby_need']"
   ],
   "id": "49a5c373970ba6bb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Datenbereinigung (Teil 1)",
   "id": "68c8344d506ab936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In der Datenanalyse wurden folgende Aspekte der Datenqualität überprüft:\n",
    "\n",
    "- **Fehlende Werte:** Es wurde festgestellt, dass keine fehlenden Werte in den Daten vorliegen. Somit sind keine Imputationsmethoden oder Auffüllstrategien notwendig.\n",
    "- **Duplikate:** Die Daten wurden auf Duplikate überprüft, und es konnte bestätigt werden, dass keine doppelten Einträge vorhanden sind. Ein Entfernen doppelter Zeilen ist daher nicht erforderlich.\n",
    "- **Ausreißer:** Während der Analyse wurden mögliche Ausreißer in den numerischen Variablen untersucht. Die vorhandenen Ausreißer scheinen jedoch alle plausibel und nachvollziehbar zu sein (z. B. Spitzenwerte bei Notrufen oder Krankenständen zu bestimmten Zeiten). Daher wurde entschieden, die Ausreißer nicht weiter zu beschneiden oder zu entfernen."
   ],
   "id": "800f6e0b7abd60b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e3f7da58696938f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Feature Engineering",
   "id": "253f58111de5616"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1. Feature Enrichment",
   "id": "359091737e48cf60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:41:25.201628Z",
     "start_time": "2024-10-30T15:41:25.116611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom Transformer für Datum-Features\n",
    "class DateFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column='date'):\n",
    "        self.date_column = date_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Dynamisch Feiertage für den Bereich des Datum-Features festlegen\n",
    "        years = range(X[self.date_column].dt.year.min(), X[self.date_column].dt.year.max() + 1)\n",
    "        self.de_holidays = holidays.Germany(years=years)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['month'] = X[self.date_column].dt.month\n",
    "        X['day_of_week'] = X[self.date_column].dt.weekday.astype('category')  # 0=Monday, 6=Sunday\n",
    "        X['quarter'] = X[self.date_column].dt.quarter.astype('category')\n",
    "        \n",
    "        # Berechnung der season vor der Typumwandlung in 'category'\n",
    "        X['season'] = (X['month'] % 12 // 3 + 1).astype('category')  # 1=Winter, 2=Spring, etc.\n",
    "        \n",
    "        # Konvertiere 'month' in Kategorie, nachdem season berechnet wurde\n",
    "        X['month'] = X['month'].astype('category')\n",
    "        X['holiday'] = X[self.date_column].apply(lambda x: 1 if x in self.de_holidays else 0).astype(bool)\n",
    "        X['weekend'] = X['day_of_week'].apply(lambda x: 1 if x >= 5 else 0).astype(bool)\n",
    "        return X\n",
    "\n",
    "# Custom Transformer für Lag- und Rolling-Features (in Englisch)\n",
    "class LagRollingFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lag_features, rolling_features, lags=[7, 30], windows=[7, 30]):\n",
    "        self.lag_features = lag_features\n",
    "        self.rolling_features = rolling_features\n",
    "        self.lags = lags\n",
    "        self.windows = windows\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for lag in self.lags:\n",
    "            for feature in self.lag_features:\n",
    "                X[f'{feature}_lag_{lag}'] = X[feature].shift(lag)\n",
    "                \n",
    "        for window in self.windows:\n",
    "            for feature in self.rolling_features:\n",
    "                X[f'{feature}_ma_{window}'] = X[feature].rolling(window=window).mean()\n",
    "                X[f'{feature}_var_{window}'] = X[feature].rolling(window=window).var()\n",
    "        \n",
    "        # Entfernen von NaN-Werten, die durch Lag- und Rolling-Features entstehen\n",
    "        X = X.dropna().reset_index(drop=True)\n",
    "        return X\n",
    "\n",
    "# Custom Transformer zum Entfernen der Datetime-Spalte\n",
    "class DropDateColumn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_column='date'):\n",
    "        self.date_column = date_column\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=[self.date_column])\n",
    "\n",
    "# Feature-Engineering-Pipeline\n",
    "feature_engineering_pipeline = Pipeline([\n",
    "    ('date_features', DateFeatureExtractor(date_column='date')),\n",
    "    ('lag_rolling_features', LagRollingFeatures(\n",
    "        lag_features=['calls', 'n_sick', 'dafted'],\n",
    "        rolling_features=['calls', 'n_sick', 'dafted']\n",
    "    )),\n",
    "    ('drop_date', DropDateColumn(date_column='date'))\n",
    "])\n",
    "\n",
    "# Pipeline auf die Daten anwenden\n",
    "df_transformed = feature_engineering_pipeline.fit_transform(X)\n",
    "df_transformed"
   ],
   "id": "a4e6526a47e27701",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      n_sick   calls  n_duty  n_sby  dafted month day_of_week quarter season  \\\n",
       "0         54  8400.0    1700     90     0.0     5           6       2      2   \n",
       "1         63  7782.0    1700     90     0.0     5           0       2      2   \n",
       "2         61  7716.0    1700     90     0.0     5           1       2      2   \n",
       "3         58  8340.0    1700     90     0.0     5           2       2      2   \n",
       "4         57  8064.0    1700     90     0.0     5           3       2      2   \n",
       "...      ...     ...     ...    ...     ...   ...         ...     ...    ...   \n",
       "1117      86  8544.0    1900     90     0.0     5           3       2      2   \n",
       "1118      81  8814.0    1900     90     0.0     5           4       2      2   \n",
       "1119      76  9846.0    1900     90    56.0     5           5       2      2   \n",
       "1120      83  9882.0    1900     90    70.0     5           6       2      2   \n",
       "1121      77  8790.0    1900     90     0.0     5           0       2      2   \n",
       "\n",
       "      holiday  ...  n_sick_ma_7  n_sick_var_7  dafted_ma_7  dafted_var_7  \\\n",
       "0        True  ...    64.000000     29.000000     0.000000      0.000000   \n",
       "1       False  ...    62.714286     16.571429     0.000000      0.000000   \n",
       "2       False  ...    62.142857     15.809524     0.000000      0.000000   \n",
       "3       False  ...    61.571429     18.285714     0.000000      0.000000   \n",
       "4        True  ...    60.285714     16.571429     0.000000      0.000000   \n",
       "...       ...  ...          ...           ...          ...           ...   \n",
       "1117    False  ...    78.571429     63.619048    26.714286   4995.571429   \n",
       "1118    False  ...    77.571429     48.619048    26.714286   4995.571429   \n",
       "1119    False  ...    78.142857     43.476190     8.000000    448.000000   \n",
       "1120    False  ...    78.857143     46.809524    18.000000    961.333333   \n",
       "1121    False  ...    77.857143     41.809524    18.000000    961.333333   \n",
       "\n",
       "      calls_ma_30  calls_var_30  n_sick_ma_30  n_sick_var_30  dafted_ma_30  \\\n",
       "0          6784.2  1.001451e+06     60.700000      49.113793      0.100000   \n",
       "1          6759.4  9.305297e+05     60.666667      48.919540      0.100000   \n",
       "2          6747.0  9.010570e+05     60.433333      47.012644      0.100000   \n",
       "3          6790.2  9.835899e+05     60.000000      43.172414      0.100000   \n",
       "4          6817.8  1.031899e+06     59.800000      43.131034      0.100000   \n",
       "...           ...           ...           ...            ...           ...   \n",
       "1117       9644.2  1.184878e+06     77.500000      39.637931     98.833333   \n",
       "1118       9581.6  1.166733e+06     77.166667      33.660920     90.833333   \n",
       "1119       9614.4  1.150174e+06     76.966667      32.860920     92.700000   \n",
       "1120       9659.4  1.110149e+06     77.066667      33.788506     95.033333   \n",
       "1121       9663.4  1.102441e+06     77.000000      33.655172     95.033333   \n",
       "\n",
       "      dafted_var_30  \n",
       "0          0.300000  \n",
       "1          0.300000  \n",
       "2          0.300000  \n",
       "3          0.300000  \n",
       "4          0.300000  \n",
       "...             ...  \n",
       "1117   16236.557471  \n",
       "1118   15820.005747  \n",
       "1119   15573.734483  \n",
       "1120   15289.550575  \n",
       "1121   15289.550575  \n",
       "\n",
       "[1122 rows x 29 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sick</th>\n",
       "      <th>calls</th>\n",
       "      <th>n_duty</th>\n",
       "      <th>n_sby</th>\n",
       "      <th>dafted</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>n_sick_ma_7</th>\n",
       "      <th>n_sick_var_7</th>\n",
       "      <th>dafted_ma_7</th>\n",
       "      <th>dafted_var_7</th>\n",
       "      <th>calls_ma_30</th>\n",
       "      <th>calls_var_30</th>\n",
       "      <th>n_sick_ma_30</th>\n",
       "      <th>n_sick_var_30</th>\n",
       "      <th>dafted_ma_30</th>\n",
       "      <th>dafted_var_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6784.2</td>\n",
       "      <td>1.001451e+06</td>\n",
       "      <td>60.700000</td>\n",
       "      <td>49.113793</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>7782.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>62.714286</td>\n",
       "      <td>16.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6759.4</td>\n",
       "      <td>9.305297e+05</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>48.919540</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>62.142857</td>\n",
       "      <td>15.809524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6747.0</td>\n",
       "      <td>9.010570e+05</td>\n",
       "      <td>60.433333</td>\n",
       "      <td>47.012644</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>8340.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>61.571429</td>\n",
       "      <td>18.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6790.2</td>\n",
       "      <td>9.835899e+05</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>43.172414</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>8064.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>60.285714</td>\n",
       "      <td>16.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6817.8</td>\n",
       "      <td>1.031899e+06</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>43.131034</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>86</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>63.619048</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>4995.571429</td>\n",
       "      <td>9644.2</td>\n",
       "      <td>1.184878e+06</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>39.637931</td>\n",
       "      <td>98.833333</td>\n",
       "      <td>16236.557471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>81</td>\n",
       "      <td>8814.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>77.571429</td>\n",
       "      <td>48.619048</td>\n",
       "      <td>26.714286</td>\n",
       "      <td>4995.571429</td>\n",
       "      <td>9581.6</td>\n",
       "      <td>1.166733e+06</td>\n",
       "      <td>77.166667</td>\n",
       "      <td>33.660920</td>\n",
       "      <td>90.833333</td>\n",
       "      <td>15820.005747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>76</td>\n",
       "      <td>9846.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>43.476190</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>9614.4</td>\n",
       "      <td>1.150174e+06</td>\n",
       "      <td>76.966667</td>\n",
       "      <td>32.860920</td>\n",
       "      <td>92.700000</td>\n",
       "      <td>15573.734483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>83</td>\n",
       "      <td>9882.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>78.857143</td>\n",
       "      <td>46.809524</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>961.333333</td>\n",
       "      <td>9659.4</td>\n",
       "      <td>1.110149e+06</td>\n",
       "      <td>77.066667</td>\n",
       "      <td>33.788506</td>\n",
       "      <td>95.033333</td>\n",
       "      <td>15289.550575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>77</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>77.857143</td>\n",
       "      <td>41.809524</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>961.333333</td>\n",
       "      <td>9663.4</td>\n",
       "      <td>1.102441e+06</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>33.655172</td>\n",
       "      <td>95.033333</td>\n",
       "      <td>15289.550575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 29 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Durch die oben genannten Schritte wurde die Zeitstruktur der Daten aufgeschlüsselt und wichtige historische Informationen eingebracht. Diese vorbereiteten Features bieten eine starke Grundlage für das Modelltraining, indem sie saisonale Muster und historische Trends berücksichtigen. Mit diesen zusätzlichen Informationen kann das Modell saisonale Zyklen und vergangenheitsbasierte Abhängigkeiten effektiver erfassen, was die Genauigkeit der Vorhersagen verbessern sollte.\n",
    "\n",
    "## 1. Zeitbasierte Features extrahieren\n",
    "- Erstellte Features:\n",
    "    - **Monat:** Gibt den Monat des jeweiligen Datums an (Werte: 1 bis 12).\n",
    "    - **Wochentag:** Gibt den Wochentag des jeweiligen Datums an (Werte: 0 für Montag bis 6 für Sonntag).\n",
    "    - **Quartal:** Zeigt an, in welchem Quartal das Datum liegt (Werte: 1 bis 4).\n",
    "    - **Jahreszeit:** Zeigt die Jahreszeit an, in der das Datum liegt (Werte: 1 für Winter, 2 für Frühling, 3 für Sommer, 4 für Herbst).\n",
    "- **Begründung:** Zeitbasierte Features sind entscheidend für Zeitreihen, da sie saisonale Muster und Zyklen erfassen. Zum Beispiel können Notrufzahlen und Krankenstände zu bestimmten Jahreszeiten oder Wochentagen höher oder niedriger sein. Durch das Hinzufügen von Features wie Monat, Wochentag, Quartal und Jahreszeit kann das Modell saisonale Schwankungen und wöchentliche Trends besser erkennen.\n",
    "\n",
    "## 2. Lag-Features erstellen\n",
    "- Erstellte Features:\n",
    "    - **Lag-Features:** Werte der Variablen Anzahl_Notrufe, Anzahl_Krankenstand, Ersatzfahrer_aktiviert und Zusätzliche_Fahrer_erforderlich mit Verzögerungen von 7 und 30 Tagen (z. B. Anzahl_Notrufe_Lag_7 und Anzahl_Notrufe_Lag_30).\n",
    "- **Begründung:** Lag-Features ermöglichen es dem Modell, auf vergangene Informationen zuzugreifen und Trends oder Muster in der Vergangenheit zu berücksichtigen. Für Zeitreihen ist es besonders nützlich zu wissen, wie sich eine Variable in den vorhergehenden Tagen entwickelt hat. Zum Beispiel könnte die Anzahl der Notrufe vor 7 oder 30 Tagen einen Einfluss auf die heutige Anzahl haben. Durch die Einführung von 7-Tage- und 30-Tage-Lags erhält das Modell Informationen über wöchentliche und monatliche Verzögerungen, was bei der Vorhersage saisonaler Muster hilft.\n",
    "\n",
    "## 3. Gleitende Durchschnitte und Varianzen berechnen\n",
    "- Erstellte Features:\n",
    "    - **Gleitende Durchschnitte:** 7-Tage- und 30-Tage-Durchschnitte der Variablen Anzahl_Notrufe, Anzahl_Krankenstand, Ersatzfahrer_aktiviert und Zusätzliche_Fahrer_erforderlich (z. B. Anzahl_Notrufe_MA_7 und Anzahl_Notrufe_MA_30).\n",
    "    - **Gleitende Varianzen:** 7-Tage- und 30-Tage-Varianzen der gleichen Variablen (z. B. Anzahl_Notrufe_Var_7 und Anzahl_Notrufe_Var_30).\n",
    "- **Begründung:** Gleitende Durchschnitte (Moving Averages) glätten kurzfristige Schwankungen und geben dem Modell ein klareres Bild von längerfristigen Trends. Die 7-Tage-Durchschnitte erfassen wöchentliche Muster, während die 30-Tage-Durchschnitte längere saisonale Trends widerspiegeln. Gleitende Varianzen (Moving Variances) geben an, wie stark die Werte innerhalb eines bestimmten Zeitfensters schwanken, was Hinweise auf die Stabilität oder Instabilität eines Merkmals geben kann. Wenn beispielsweise die Varianz in den Krankenständen in bestimmten Zeitfenstern hoch ist, könnte dies auf besondere Ereignisse oder Einflüsse hindeuten.\n",
    "\n",
    "## 4. Entfernen von NaN-Werten\n",
    "- Durchgeführte Schritte:\n",
    "    - Entfernen von Zeilen mit NaN-Werten, die durch die Erstellung der Lag- und Moving Average-Features entstanden sind.\n",
    "- **Begründung:** Lag- und Rolling-Funktionen erzeugen am Anfang der Zeitreihe NaN-Werte, da für die ersten Zeilen keine Daten für die Berechnung der zurückliegenden Tage vorhanden sind. Diese Zeilen wurden entfernt, da sie keine vollständigen Daten enthalten und daher für das Modelltraining ungeeignet wären.\n",
    "\n",
    "## 5. Feiertag\n",
    "- **Beschreibung:** In der Spalte Feiertag wird überprüft, ob das jeweilige Datum in die Liste der deutschen Feiertage fällt. Dies wurde mithilfe der holidays-Bibliothek umgesetzt, die für Deutschland und spezifische Jahre Feiertage ausgibt. Für Feiertage erhält das Feature den Wert 1, für normale Tage den Wert 0.\n",
    " \n",
    "- **Begründung:** Feiertage können einen wesentlichen Einfluss auf das Verhalten und die Nachfrage im Rettungsdienst haben. An Feiertagen kann es z. B. zu einer erhöhten Anzahl von Notrufen kommen (z. B. an Silvester) oder die Krankenstände können abweichen. Diese Tage haben oft einzigartige Muster, die ein Modell ohne Berücksichtigung der Feiertage nicht erkennen könnte. Durch das Hinzufügen dieses Features erhält das Modell zusätzliche Informationen, die helfen, besondere Tage zu identifizieren und diese in der Prognose zu berücksichtigen.\n",
    "## 6. Wochenende\n",
    "- **Beschreibung:** Die Spalte Wochenende gibt an, ob das Datum auf ein Wochenende fällt (Samstag oder Sonntag). Dabei erhalten Samstage und Sonntage den Wert 1, alle anderen Tage den Wert 0.\n",
    "\n",
    "- **Begründung:** Wochenenden haben häufig andere Muster im Vergleich zu Werktagen, sowohl in Bezug auf Notrufe als auch auf Krankenstände. Beispielsweise kann die Anzahl der Notrufe am Wochenende variieren, da die Aktivität in der Bevölkerung anders ist als an Werktagen. Auch die Krankenstände könnten am Wochenende anders verlaufen. Dieses Feature hilft dem Modell, die Unterschiede zwischen Wochentagen und Wochenenden zu lernen und die Vorhersage entsprechend zu verbessern.\n"
   ],
   "id": "b53c3876242707bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2. Scaling und Encoding",
   "id": "d00ac13acf0c1762"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:41:53.177690Z",
     "start_time": "2024-10-30T15:41:53.153598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Pipeline für Lineare Regression (nur Scaling und Encoding)\n",
    "preprocessor_lr = Pipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "            ('cat', OneHotEncoder(drop='first'), make_column_selector(dtype_include='category'))\n",
    "        ], remainder='passthrough'))  # Alle übrigen Spalten im Originalzustand belassen\n",
    "])\n",
    "\n",
    "# Pipeline für Tree-basierte Modelle (nur Encoding, keine Skalierung)\n",
    "preprocessor_tree = Pipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "            ('cat', OneHotEncoder(drop='first'), make_column_selector(dtype_include='category'))\n",
    "        ], remainder='passthrough'))  # Alle übrigen Spalten im Originalzustand belassen\n",
    "])\n",
    "\n",
    "# Anwendung der Pipeline auf die Daten\n",
    "df_transformed_scaled_encoded = preprocessor_tree.fit_transform(df_transformed)\n",
    "\n",
    "df_transformed_scaled_encoded"
   ],
   "id": "4d77f42918e4500d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.400e+01, 8.400e+03, 1.700e+03, ..., 0.000e+00, 1.000e+00,\n",
       "        1.000e+00],\n",
       "       [6.300e+01, 7.782e+03, 1.700e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [6.100e+01, 7.716e+03, 1.700e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [7.600e+01, 9.846e+03, 1.900e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [8.300e+01, 9.882e+03, 1.900e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [7.700e+01, 8.790e+03, 1.900e+03, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#### Feature Selection einfügen ###############",
   "id": "bdc7ca9ac0559500"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modellabhängige Datenvorbereitung\n",
    "Ich habe mich entschieden, unterschiedliche Pipelines für verschiedene Modellgruppen zu definieren, um eine effiziente und modellgerechte Datenvorbereitung zu ermöglichen. Zusätzlich habe ich PCA und Feature Selection integriert, um die Dimensionen zu reduzieren und die relevantesten Merkmale für jedes Modell hervorzuheben.\n",
    "\n",
    "- Lineare Regression (Baseline-Modell)\n",
    "    - **Zweck:** Die Lineare Regression dient als Baseline-Modell, um die Modellleistung mit einer einfachen, interpretierten Methode zu vergleichen.\n",
    "    - **Encoding und Skalierung:** Für die Lineare Regression verwende ich One-Hot-Encoding für die kategorischen Variablen (Monat, Wochentag, Quartal, Jahreszeit), um den linearen Zusammenhang zwischen den einzelnen Kategorien und dem Zielwert explizit zu erfassen. Zudem wird ein StandardScaler auf die numerischen Variablen angewendet, da lineare Modelle empfindlich auf unterschiedliche Skalen reagieren.\n",
    "    - **PCA:** Zusätzlich habe ich PCA (Principal Component Analysis) in die Pipeline integriert, um die Anzahl der Merkmale zu reduzieren und so die Berechnungen zu beschleunigen. Die PCA ist besonders hilfreich für die Lineare Regression, da sie das Modell auf die wichtigsten Hauptkomponenten fokussiert, ohne die interpretierbare Varianz zu verlieren. Die Anzahl der Hauptkomponenten wurde so gewählt, dass 95 % der Varianz erhalten bleiben, was eine gute Balance zwischen Komplexitätsreduktion und Informationserhalt bietet.\n",
    "\n",
    "- Random Forest und Gradient Boosting\n",
    "    - **Zweck:** Diese Modelle sind in der Lage, nichtlineare Zusammenhänge und Interaktionen zwischen den Variablen zu erfassen und robust gegen Ausreißer.\n",
    "    - **Encoding und Skalierung:** Da baumbasierte Modelle unempfindlich gegenüber unterschiedlichen Skalen sind, lasse ich die numerischen Variablen unverändert (passthrough). Bei den kategorischen Variablen setze ich One-Hot-Encoding ein, um die Interpretierbarkeit der Features zu erhöhen und Redundanzen in den Baumstrukturen zu vermeiden. Alternativ könnte auch ein Label-Encoding für größere Datensätze verwendet werden, wenn Rechenzeit optimiert werden soll.\n"
   ],
   "id": "dca0c99b7afa6bbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train-Test-Split",
   "id": "5d1fcc228c3514c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setze die Zielvariable\n",
    "target = 'Ersatzfahrer_aktiviert'\n",
    "\n",
    "# Definiere die Merkmale (X) und die Zielvariable (y)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Führe einen zeitlichen Train-Test-Split durch (80 % Training, 20 % Test) mit shuffle=False\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Überprüfen der Aufteilung\n",
    "print(\"Training Set Größe:\", X_train.shape, y_train.shape)\n",
    "print(\"Test Set Größe:\", X_test.shape, y_test.shape)"
   ],
   "id": "a370f129ff077298",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nach dem Data Preprocessing (Bereinigung und Enrichment) habe ich die Daten in Trainings- und Testsets aufgeteilt. Diese Aufteilung dient dazu, das Modell auf historischen Daten zu trainieren und seine Leistung auf zukünftigen, bislang unbekannten Daten zu bewerten. Dies ist besonders wichtig für die Zeitreihenprognose, da wir sicherstellen möchten, dass das Modell keine „Zukunftsinformationen“ aus dem Testset erhält.\n",
    "\n",
    "# Begründung\n",
    "- **Vermeidung von Datenlecks:** Da es sich um zeitbasierte Daten handelt, ist es entscheidend, dass die Testdaten den Modellaufbau nicht beeinflussen, um die zukünftige Vorhersageleistung korrekt abzubilden. Ein zeitlicher Split verhindert, dass Informationen aus der „Zukunft“ in das Modelltraining einfließen.\n",
    "- **Replizierbarkeit und Robustheit:** Die feste Datenaufteilung gewährleistet, dass die Modellleistung auch bei zukünftigen Daten realistisch ist und nicht auf Muster im Testset abgestimmt wurde.\n",
    "- **Verallgemeinerungsfähigkeit:** Dieser Ansatz stellt sicher, dass das Modell generalisiert und saisonale Trends sowie kurzfristige Schwankungen auf Basis der Trainingsdaten erkennt."
   ],
   "id": "f773cfd91e3c7b0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speicherung der prozessierten Daten",
   "id": "ecd501737f0e4884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T15:40:49.211012Z",
     "start_time": "2024-10-30T15:40:49.205989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sicherstellen, dass der Ordner 'data/processed' existiert\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Speichern der Trainings- und Testdaten für lineare Modelle\n",
    "pd.DataFrame(X_train_lr_pca).to_csv('../data/processed/X_train_lr_pca.csv', index=False)\n",
    "pd.DataFrame(X_test_lr_pca).to_csv('../data/processed/X_test_lr_pca.csv', index=False)\n",
    "\n",
    "# Speichern der Trainings- und Testdaten für baumbasierte Modelle\n",
    "pd.DataFrame(X_train_tree_fs).to_csv('../data/processed/X_train_tree_fs.csv', index=False)\n",
    "pd.DataFrame(X_test_tree_fs).to_csv('../data/processed/X_test_tree_fs.csv', index=False)\n",
    "\n",
    "# Zielwerte speichern\n",
    "pd.DataFrame(y_train).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.DataFrame(y_test).to_csv('../data/processed/y_test.csv', index=False)"
   ],
   "id": "8d2b77730cd3120c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
