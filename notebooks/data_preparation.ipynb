{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Preparation",
   "id": "70682b6a9a6861f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.382420Z",
     "start_time": "2024-10-29T15:29:40.711129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import os\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ],
   "id": "e1eef165a7028e8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.403491Z",
     "start_time": "2024-10-29T15:29:42.383427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Laden der Daten\n",
    "# Passe den Pfad entsprechend an, falls die Daten in einem spezifischen Ordner liegen\n",
    "df = pd.read_csv('../data/raw/sickness_table.csv', parse_dates=['date'])"
   ],
   "id": "776cc4fb00d1a906",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.414156Z",
     "start_time": "2024-10-29T15:29:42.407513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Unnötige Index-Spalte ignorieren\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ],
   "id": "3422d781227689de",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.441420Z",
     "start_time": "2024-10-29T15:29:42.416180Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "8104cc299458e7bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  n_sick   calls  n_duty  n_sby  sby_need  dafted\n",
       "0    2016-04-01      73  8154.0    1700     90       4.0     0.0\n",
       "1    2016-04-02      64  8526.0    1700     90      70.0     0.0\n",
       "2    2016-04-03      68  8088.0    1700     90       0.0     0.0\n",
       "3    2016-04-04      71  7044.0    1700     90       0.0     0.0\n",
       "4    2016-04-05      63  7236.0    1700     90       0.0     0.0\n",
       "...         ...     ...     ...     ...    ...       ...     ...\n",
       "1147 2019-05-23      86  8544.0    1900     90       0.0     0.0\n",
       "1148 2019-05-24      81  8814.0    1900     90       0.0     0.0\n",
       "1149 2019-05-25      76  9846.0    1900     90     146.0    56.0\n",
       "1150 2019-05-26      83  9882.0    1900     90     160.0    70.0\n",
       "1151 2019-05-27      77  8790.0    1900     90       0.0     0.0\n",
       "\n",
       "[1152 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>n_sick</th>\n",
       "      <th>calls</th>\n",
       "      <th>n_duty</th>\n",
       "      <th>n_sby</th>\n",
       "      <th>sby_need</th>\n",
       "      <th>dafted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>73</td>\n",
       "      <td>8154.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>64</td>\n",
       "      <td>8526.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>68</td>\n",
       "      <td>8088.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>71</td>\n",
       "      <td>7044.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>63</td>\n",
       "      <td>7236.0</td>\n",
       "      <td>1700</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>86</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>81</td>\n",
       "      <td>8814.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>76</td>\n",
       "      <td>9846.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>146.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>83</td>\n",
       "      <td>9882.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>160.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>77</td>\n",
       "      <td>8790.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.451035Z",
     "start_time": "2024-10-29T15:29:42.442439Z"
    }
   },
   "cell_type": "code",
   "source": "# Übersetzen der ",
   "id": "20ae85ba8ea26b6b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Datenbereinigung (Teil 1)",
   "id": "68c8344d506ab936"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In der Datenanalyse wurden folgende Aspekte der Datenqualität überprüft:\n",
    "\n",
    "- **Fehlende Werte:** Es wurde festgestellt, dass keine fehlenden Werte in den Daten vorliegen. Somit sind keine Imputationsmethoden oder Auffüllstrategien notwendig.\n",
    "- **Duplikate:** Die Daten wurden auf Duplikate überprüft, und es konnte bestätigt werden, dass keine doppelten Einträge vorhanden sind. Ein Entfernen doppelter Zeilen ist daher nicht erforderlich.\n",
    "- **Ausreißer:** Während der Analyse wurden mögliche Ausreißer in den numerischen Variablen untersucht. Die vorhandenen Ausreißer scheinen jedoch alle plausibel und nachvollziehbar zu sein (z. B. Spitzenwerte bei Notrufen oder Krankenständen zu bestimmten Zeiten). Daher wurde entschieden, die Ausreißer nicht weiter zu beschneiden oder zu entfernen."
   ],
   "id": "800f6e0b7abd60b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.468327Z",
     "start_time": "2024-10-29T15:29:42.453068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Float-Spalten in int64 umwandeln (calls, sby_need und dafted)\n",
    "df['calls'] = df['calls'].astype('int64')\n",
    "df['sby_need'] = df['sby_need'].astype('int64')\n",
    "df['dafted'] = df['dafted'].astype('int64')"
   ],
   "id": "922c859d043df59f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.482297Z",
     "start_time": "2024-10-29T15:29:42.470354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spaltennamen ins Deutsche übersetzen\n",
    "df = df.rename(columns={\n",
    "    'date': 'Datum',\n",
    "    'n_sick': 'Anzahl_Krankenstand',\n",
    "    'calls': 'Anzahl_Notrufe',\n",
    "    'n_duty': 'Anzahl_im_Dienst',\n",
    "    'n_sby': 'Anzahl_Ersatzfahrer_Bereitschaft',\n",
    "    'sby_need': 'Ersatzfahrer_aktiviert',\n",
    "    'dafted': 'Zusätzliche_Fahrer_erforderlich'\n",
    "})"
   ],
   "id": "1c0f6ad3503cfee0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e3f7da58696938f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Feature Engineering",
   "id": "253f58111de5616"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.494929Z",
     "start_time": "2024-10-29T15:29:42.484298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Monat, Wochentag, Quartal und Jahreszeit aus dem Datum extrahieren\n",
    "df['Monat'] = df['Datum'].dt.month\n",
    "df['Wochentag'] = df['Datum'].dt.dayofweek  # 0=Montag, 6=Sonntag\n",
    "df['Quartal'] = df['Datum'].dt.quarter\n",
    "df['Jahreszeit'] = df['Monat'] % 12 // 3 + 1  # 1=Winter, 2=Frühling, 3=Sommer, 4=Herbst\n"
   ],
   "id": "fbbd62688c6edd60",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.510795Z",
     "start_time": "2024-10-29T15:29:42.497945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lag-Features für 7 und 30 Tage für relevante Spalten erstellen\n",
    "for lag in [7, 30]:\n",
    "    df[f'Anzahl_Notrufe_Lag_{lag}'] = df['Anzahl_Notrufe'].shift(lag)\n",
    "    df[f'Anzahl_Krankenstand_Lag_{lag}'] = df['Anzahl_Krankenstand'].shift(lag)\n",
    "    df[f'Ersatzfahrer_aktiviert_Lag_{lag}'] = df['Ersatzfahrer_aktiviert'].shift(lag)\n",
    "    df[f'Zusätzliche_Fahrer_erforderlich_Lag_{lag}'] = df['Zusätzliche_Fahrer_erforderlich'].shift(lag)\n"
   ],
   "id": "be0906bbb418a2eb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.550587Z",
     "start_time": "2024-10-29T15:29:42.515818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Berechnung von 7-Tage und 30-Tage gleitenden Durchschnitten und Varianzen\n",
    "for window in [7, 30]:\n",
    "    df[f'Anzahl_Notrufe_MA_{window}'] = df['Anzahl_Notrufe'].rolling(window=window).mean()\n",
    "    df[f'Anzahl_Krankenstand_MA_{window}'] = df['Anzahl_Krankenstand'].rolling(window=window).mean()\n",
    "    df[f'Ersatzfahrer_aktiviert_MA_{window}'] = df['Ersatzfahrer_aktiviert'].rolling(window=window).mean()\n",
    "    df[f'Zusätzliche_Fahrer_erforderlich_MA_{window}'] = df['Zusätzliche_Fahrer_erforderlich'].rolling(window=window).mean()\n",
    "\n",
    "    df[f'Anzahl_Notrufe_Var_{window}'] = df['Anzahl_Notrufe'].rolling(window=window).var()\n",
    "    df[f'Anzahl_Krankenstand_Var_{window}'] = df['Anzahl_Krankenstand'].rolling(window=window).var()\n",
    "    df[f'Ersatzfahrer_aktiviert_Var_{window}'] = df['Ersatzfahrer_aktiviert'].rolling(window=window).var()\n",
    "    df[f'Zusätzliche_Fahrer_erforderlich_Var_{window}'] = df['Zusätzliche_Fahrer_erforderlich'].rolling(window=window).var()\n"
   ],
   "id": "eea4d58e46cd25dd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.573699Z",
     "start_time": "2024-10-29T15:29:42.552593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Entfernen von Zeilen mit NaN-Werten (bedingt durch Lag- und Rolling-Features)\n",
    "df = df.dropna().reset_index(drop=True)"
   ],
   "id": "801d269976369e31",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Durch die oben genannten Schritte wurde die Zeitstruktur der Daten aufgeschlüsselt und wichtige historische Informationen eingebracht. Diese vorbereiteten Features bieten eine starke Grundlage für das Modelltraining, indem sie saisonale Muster und historische Trends berücksichtigen. Mit diesen zusätzlichen Informationen kann das Modell saisonale Zyklen und vergangenheitsbasierte Abhängigkeiten effektiver erfassen, was die Genauigkeit der Vorhersagen verbessern sollte.\n",
    "\n",
    "## 1. Zeitbasierte Features extrahieren\n",
    "- Erstellte Features:\n",
    "    - **Monat:** Gibt den Monat des jeweiligen Datums an (Werte: 1 bis 12).\n",
    "    - **Wochentag:** Gibt den Wochentag des jeweiligen Datums an (Werte: 0 für Montag bis 6 für Sonntag).\n",
    "    - **Quartal:** Zeigt an, in welchem Quartal das Datum liegt (Werte: 1 bis 4).\n",
    "    - **Jahreszeit:** Zeigt die Jahreszeit an, in der das Datum liegt (Werte: 1 für Winter, 2 für Frühling, 3 für Sommer, 4 für Herbst).\n",
    "- **Begründung:** Zeitbasierte Features sind entscheidend für Zeitreihen, da sie saisonale Muster und Zyklen erfassen. Zum Beispiel können Notrufzahlen und Krankenstände zu bestimmten Jahreszeiten oder Wochentagen höher oder niedriger sein. Durch das Hinzufügen von Features wie Monat, Wochentag, Quartal und Jahreszeit kann das Modell saisonale Schwankungen und wöchentliche Trends besser erkennen.\n",
    "\n",
    "## 2. Lag-Features erstellen\n",
    "- Erstellte Features:\n",
    "    - **Lag-Features:** Werte der Variablen Anzahl_Notrufe, Anzahl_Krankenstand, Ersatzfahrer_aktiviert und Zusätzliche_Fahrer_erforderlich mit Verzögerungen von 7 und 30 Tagen (z. B. Anzahl_Notrufe_Lag_7 und Anzahl_Notrufe_Lag_30).\n",
    "- **Begründung:** Lag-Features ermöglichen es dem Modell, auf vergangene Informationen zuzugreifen und Trends oder Muster in der Vergangenheit zu berücksichtigen. Für Zeitreihen ist es besonders nützlich zu wissen, wie sich eine Variable in den vorhergehenden Tagen entwickelt hat. Zum Beispiel könnte die Anzahl der Notrufe vor 7 oder 30 Tagen einen Einfluss auf die heutige Anzahl haben. Durch die Einführung von 7-Tage- und 30-Tage-Lags erhält das Modell Informationen über wöchentliche und monatliche Verzögerungen, was bei der Vorhersage saisonaler Muster hilft.\n",
    "\n",
    "## 3. Gleitende Durchschnitte und Varianzen berechnen\n",
    "- Erstellte Features:\n",
    "    - **Gleitende Durchschnitte:** 7-Tage- und 30-Tage-Durchschnitte der Variablen Anzahl_Notrufe, Anzahl_Krankenstand, Ersatzfahrer_aktiviert und Zusätzliche_Fahrer_erforderlich (z. B. Anzahl_Notrufe_MA_7 und Anzahl_Notrufe_MA_30).\n",
    "    - **Gleitende Varianzen:** 7-Tage- und 30-Tage-Varianzen der gleichen Variablen (z. B. Anzahl_Notrufe_Var_7 und Anzahl_Notrufe_Var_30).\n",
    "- **Begründung:** Gleitende Durchschnitte (Moving Averages) glätten kurzfristige Schwankungen und geben dem Modell ein klareres Bild von längerfristigen Trends. Die 7-Tage-Durchschnitte erfassen wöchentliche Muster, während die 30-Tage-Durchschnitte längere saisonale Trends widerspiegeln. Gleitende Varianzen (Moving Variances) geben an, wie stark die Werte innerhalb eines bestimmten Zeitfensters schwanken, was Hinweise auf die Stabilität oder Instabilität eines Merkmals geben kann. Wenn beispielsweise die Varianz in den Krankenständen in bestimmten Zeitfenstern hoch ist, könnte dies auf besondere Ereignisse oder Einflüsse hindeuten.\n",
    "\n",
    "## 4. Entfernen von NaN-Werten\n",
    "- Durchgeführte Schritte:\n",
    "    - Entfernen von Zeilen mit NaN-Werten, die durch die Erstellung der Lag- und Moving Average-Features entstanden sind.\n",
    "- **Begründung:** Lag- und Rolling-Funktionen erzeugen am Anfang der Zeitreihe NaN-Werte, da für die ersten Zeilen keine Daten für die Berechnung der zurückliegenden Tage vorhanden sind. Diese Zeilen wurden entfernt, da sie keine vollständigen Daten enthalten und daher für das Modelltraining ungeeignet wären.\n"
   ],
   "id": "b53c3876242707bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.921739Z",
     "start_time": "2024-10-29T15:29:42.579698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Deutsche Feiertage für relevante Jahre erstellen\n",
    "de_holidays = holidays.Germany(years=range(df['Datum'].dt.year.min(), df['Datum'].dt.year.max() + 1))\n"
   ],
   "id": "c26fc206e430303c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.935639Z",
     "start_time": "2024-10-29T15:29:42.922759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Neues Feature hinzufügen: Feiertag (1 = Feiertag, 0 = kein Feiertag)\n",
    "df['Feiertag'] = df['Datum'].apply(lambda x: 1 if x in de_holidays else 0)"
   ],
   "id": "5279e6663ba92184",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.948864Z",
     "start_time": "2024-10-29T15:29:42.938675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wochenende hinzufügen (1 = Wochenende, 0 = kein Wochenende)\n",
    "df['Wochenende'] = df['Datum'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)"
   ],
   "id": "512b63412003e5a0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Feiertag\n",
    "- **Beschreibung:** In der Spalte Feiertag wird überprüft, ob das jeweilige Datum in die Liste der deutschen Feiertage fällt. Dies wurde mithilfe der holidays-Bibliothek umgesetzt, die für Deutschland und spezifische Jahre Feiertage ausgibt. Für Feiertage erhält das Feature den Wert 1, für normale Tage den Wert 0.\n",
    " \n",
    "- **Begründung:** Feiertage können einen wesentlichen Einfluss auf das Verhalten und die Nachfrage im Rettungsdienst haben. An Feiertagen kann es z. B. zu einer erhöhten Anzahl von Notrufen kommen (z. B. an Silvester) oder die Krankenstände können abweichen. Diese Tage haben oft einzigartige Muster, die ein Modell ohne Berücksichtigung der Feiertage nicht erkennen könnte. Durch das Hinzufügen dieses Features erhält das Modell zusätzliche Informationen, die helfen, besondere Tage zu identifizieren und diese in der Prognose zu berücksichtigen.\n",
    "## 6. Wochenende\n",
    "- **Beschreibung:** Die Spalte Wochenende gibt an, ob das Datum auf ein Wochenende fällt (Samstag oder Sonntag). Dabei erhalten Samstage und Sonntage den Wert 1, alle anderen Tage den Wert 0.\n",
    "\n",
    "- **Begründung:** Wochenenden haben häufig andere Muster im Vergleich zu Werktagen, sowohl in Bezug auf Notrufe als auch auf Krankenstände. Beispielsweise kann die Anzahl der Notrufe am Wochenende variieren, da die Aktivität in der Bevölkerung anders ist als an Werktagen. Auch die Krankenstände könnten am Wochenende anders verlaufen. Dieses Feature hilft dem Modell, die Unterschiede zwischen Wochentagen und Wochenenden zu lernen und die Vorhersage entsprechend zu verbessern."
   ],
   "id": "1b2baf58281b4fc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Anpassen der Datentypen",
   "id": "448fc55240544b6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:42.978501Z",
     "start_time": "2024-10-29T15:29:42.952883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kategorische Variablen als \"category\" festlegen\n",
    "df['Monat'] = df['Monat'].astype('category')\n",
    "df['Wochentag'] = df['Wochentag'].astype('category')\n",
    "df['Quartal'] = df['Quartal'].astype('category')\n",
    "df['Jahreszeit'] = df['Jahreszeit'].astype('category')\n",
    "\n",
    "# Binäre Variablen als \"bool\" festlegen\n",
    "df['Feiertag'] = df['Feiertag'].astype(bool)\n",
    "df['Wochenende'] = df['Wochenende'].astype(bool)"
   ],
   "id": "2feb579262a0f24c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:43.011078Z",
     "start_time": "2024-10-29T15:29:42.982505Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "184cf06db8e574dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1122 entries, 0 to 1121\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                  Non-Null Count  Dtype         \n",
      "---  ------                                  --------------  -----         \n",
      " 0   Datum                                   1122 non-null   datetime64[ns]\n",
      " 1   Anzahl_Krankenstand                     1122 non-null   int64         \n",
      " 2   Anzahl_Notrufe                          1122 non-null   int64         \n",
      " 3   Anzahl_im_Dienst                        1122 non-null   int64         \n",
      " 4   Anzahl_Ersatzfahrer_Bereitschaft        1122 non-null   int64         \n",
      " 5   Ersatzfahrer_aktiviert                  1122 non-null   int64         \n",
      " 6   Zusätzliche_Fahrer_erforderlich         1122 non-null   int64         \n",
      " 7   Monat                                   1122 non-null   category      \n",
      " 8   Wochentag                               1122 non-null   category      \n",
      " 9   Quartal                                 1122 non-null   category      \n",
      " 10  Jahreszeit                              1122 non-null   category      \n",
      " 11  Anzahl_Notrufe_Lag_7                    1122 non-null   float64       \n",
      " 12  Anzahl_Krankenstand_Lag_7               1122 non-null   float64       \n",
      " 13  Ersatzfahrer_aktiviert_Lag_7            1122 non-null   float64       \n",
      " 14  Zusätzliche_Fahrer_erforderlich_Lag_7   1122 non-null   float64       \n",
      " 15  Anzahl_Notrufe_Lag_30                   1122 non-null   float64       \n",
      " 16  Anzahl_Krankenstand_Lag_30              1122 non-null   float64       \n",
      " 17  Ersatzfahrer_aktiviert_Lag_30           1122 non-null   float64       \n",
      " 18  Zusätzliche_Fahrer_erforderlich_Lag_30  1122 non-null   float64       \n",
      " 19  Anzahl_Notrufe_MA_7                     1122 non-null   float64       \n",
      " 20  Anzahl_Krankenstand_MA_7                1122 non-null   float64       \n",
      " 21  Ersatzfahrer_aktiviert_MA_7             1122 non-null   float64       \n",
      " 22  Zusätzliche_Fahrer_erforderlich_MA_7    1122 non-null   float64       \n",
      " 23  Anzahl_Notrufe_Var_7                    1122 non-null   float64       \n",
      " 24  Anzahl_Krankenstand_Var_7               1122 non-null   float64       \n",
      " 25  Ersatzfahrer_aktiviert_Var_7            1122 non-null   float64       \n",
      " 26  Zusätzliche_Fahrer_erforderlich_Var_7   1122 non-null   float64       \n",
      " 27  Anzahl_Notrufe_MA_30                    1122 non-null   float64       \n",
      " 28  Anzahl_Krankenstand_MA_30               1122 non-null   float64       \n",
      " 29  Ersatzfahrer_aktiviert_MA_30            1122 non-null   float64       \n",
      " 30  Zusätzliche_Fahrer_erforderlich_MA_30   1122 non-null   float64       \n",
      " 31  Anzahl_Notrufe_Var_30                   1122 non-null   float64       \n",
      " 32  Anzahl_Krankenstand_Var_30              1122 non-null   float64       \n",
      " 33  Ersatzfahrer_aktiviert_Var_30           1122 non-null   float64       \n",
      " 34  Zusätzliche_Fahrer_erforderlich_Var_30  1122 non-null   float64       \n",
      " 35  Feiertag                                1122 non-null   bool          \n",
      " 36  Wochenende                              1122 non-null   bool          \n",
      "dtypes: bool(2), category(4), datetime64[ns](1), float64(24), int64(6)\n",
      "memory usage: 279.3 KB\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Kategorische Variablen (category):** Die Variablen Monat, Wochentag, Quartal und Jahreszeit sind als category definiert, was für spätere One-Hot-Encodings und ähnliche Transformationen nützlich ist.\n",
    "- **Binäre Variablen (bool):** Die Variablen Feiertag und Wochenende sind als bool definiert, da sie nur zwei mögliche Werte haben (True/False) und als logische Indikatoren dienen."
   ],
   "id": "de7ac87da02429b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:43.032445Z",
     "start_time": "2024-10-29T15:29:43.014097Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "fb0a14bfe7750ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1122 entries, 0 to 1121\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                  Non-Null Count  Dtype         \n",
      "---  ------                                  --------------  -----         \n",
      " 0   Datum                                   1122 non-null   datetime64[ns]\n",
      " 1   Anzahl_Krankenstand                     1122 non-null   int64         \n",
      " 2   Anzahl_Notrufe                          1122 non-null   int64         \n",
      " 3   Anzahl_im_Dienst                        1122 non-null   int64         \n",
      " 4   Anzahl_Ersatzfahrer_Bereitschaft        1122 non-null   int64         \n",
      " 5   Ersatzfahrer_aktiviert                  1122 non-null   int64         \n",
      " 6   Zusätzliche_Fahrer_erforderlich         1122 non-null   int64         \n",
      " 7   Monat                                   1122 non-null   category      \n",
      " 8   Wochentag                               1122 non-null   category      \n",
      " 9   Quartal                                 1122 non-null   category      \n",
      " 10  Jahreszeit                              1122 non-null   category      \n",
      " 11  Anzahl_Notrufe_Lag_7                    1122 non-null   float64       \n",
      " 12  Anzahl_Krankenstand_Lag_7               1122 non-null   float64       \n",
      " 13  Ersatzfahrer_aktiviert_Lag_7            1122 non-null   float64       \n",
      " 14  Zusätzliche_Fahrer_erforderlich_Lag_7   1122 non-null   float64       \n",
      " 15  Anzahl_Notrufe_Lag_30                   1122 non-null   float64       \n",
      " 16  Anzahl_Krankenstand_Lag_30              1122 non-null   float64       \n",
      " 17  Ersatzfahrer_aktiviert_Lag_30           1122 non-null   float64       \n",
      " 18  Zusätzliche_Fahrer_erforderlich_Lag_30  1122 non-null   float64       \n",
      " 19  Anzahl_Notrufe_MA_7                     1122 non-null   float64       \n",
      " 20  Anzahl_Krankenstand_MA_7                1122 non-null   float64       \n",
      " 21  Ersatzfahrer_aktiviert_MA_7             1122 non-null   float64       \n",
      " 22  Zusätzliche_Fahrer_erforderlich_MA_7    1122 non-null   float64       \n",
      " 23  Anzahl_Notrufe_Var_7                    1122 non-null   float64       \n",
      " 24  Anzahl_Krankenstand_Var_7               1122 non-null   float64       \n",
      " 25  Ersatzfahrer_aktiviert_Var_7            1122 non-null   float64       \n",
      " 26  Zusätzliche_Fahrer_erforderlich_Var_7   1122 non-null   float64       \n",
      " 27  Anzahl_Notrufe_MA_30                    1122 non-null   float64       \n",
      " 28  Anzahl_Krankenstand_MA_30               1122 non-null   float64       \n",
      " 29  Ersatzfahrer_aktiviert_MA_30            1122 non-null   float64       \n",
      " 30  Zusätzliche_Fahrer_erforderlich_MA_30   1122 non-null   float64       \n",
      " 31  Anzahl_Notrufe_Var_30                   1122 non-null   float64       \n",
      " 32  Anzahl_Krankenstand_Var_30              1122 non-null   float64       \n",
      " 33  Ersatzfahrer_aktiviert_Var_30           1122 non-null   float64       \n",
      " 34  Zusätzliche_Fahrer_erforderlich_Var_30  1122 non-null   float64       \n",
      " 35  Feiertag                                1122 non-null   bool          \n",
      " 36  Wochenende                              1122 non-null   bool          \n",
      "dtypes: bool(2), category(4), datetime64[ns](1), float64(24), int64(6)\n",
      "memory usage: 279.3 KB\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train-Test-Split",
   "id": "5d1fcc228c3514c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:29:43.059529Z",
     "start_time": "2024-10-29T15:29:43.033460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setze die Zielvariable\n",
    "target = 'Ersatzfahrer_aktiviert'\n",
    "\n",
    "# Definiere die Merkmale (X) und die Zielvariable (y)\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Führe einen zeitlichen Train-Test-Split durch (80 % Training, 20 % Test) mit shuffle=False\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Überprüfen der Aufteilung\n",
    "print(\"Training Set Größe:\", X_train.shape, y_train.shape)\n",
    "print(\"Test Set Größe:\", X_test.shape, y_test.shape)"
   ],
   "id": "a370f129ff077298",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Größe: (897, 36) (897,)\n",
      "Test Set Größe: (225, 36) (225,)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nach dem Data Preprocessing (Bereinigung und Enrichment) habe ich die Daten in Trainings- und Testsets aufgeteilt. Diese Aufteilung dient dazu, das Modell auf historischen Daten zu trainieren und seine Leistung auf zukünftigen, bislang unbekannten Daten zu bewerten. Dies ist besonders wichtig für die Zeitreihenprognose, da wir sicherstellen möchten, dass das Modell keine „Zukunftsinformationen“ aus dem Testset erhält.\n",
    "\n",
    "# Begründung\n",
    "- **Vermeidung von Datenlecks:** Da es sich um zeitbasierte Daten handelt, ist es entscheidend, dass die Testdaten den Modellaufbau nicht beeinflussen, um die zukünftige Vorhersageleistung korrekt abzubilden. Ein zeitlicher Split verhindert, dass Informationen aus der „Zukunft“ in das Modelltraining einfließen.\n",
    "- **Replizierbarkeit und Robustheit:** Die feste Datenaufteilung gewährleistet, dass die Modellleistung auch bei zukünftigen Daten realistisch ist und nicht auf Muster im Testset abgestimmt wurde.\n",
    "- **Verallgemeinerungsfähigkeit:** Dieser Ansatz stellt sicher, dass das Modell generalisiert und saisonale Trends sowie kurzfristige Schwankungen auf Basis der Trainingsdaten erkennt."
   ],
   "id": "f773cfd91e3c7b0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Encoding, Skalierung und PCA bzw. Feature Selection",
   "id": "8ef0936036125a4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:41:20.316188Z",
     "start_time": "2024-10-29T15:41:20.075700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Merkmalsauswahl über Datentypen\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# 1. ColumnTransformer für Lineare Regression und Neuronale Netze mit PCA\n",
    "preprocessor_lr_pca = Pipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "        ])),\n",
    "    ('pca', PCA(n_components=0.95))  # Behalte 95% der Varianz\n",
    "])\n",
    "\n",
    "# 2. ColumnTransformer für Random Forest und Gradient Boosting ohne Feature Selection\n",
    "preprocessor_tree_fs = Pipeline(steps=[\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)  # Alternativ: Label-Encoding\n",
    "        ]))\n",
    "])\n",
    "\n",
    "# 3. Fit und Transform für Trainingsdaten\n",
    "X_train_lr_pca = preprocessor_lr_pca.fit_transform(X_train, y_train)\n",
    "X_train_tree_fs = preprocessor_tree_fs.fit_transform(X_train, y_train)\n",
    "\n",
    "# 4. Transform für Testdaten\n",
    "X_test_lr_pca = preprocessor_lr_pca.transform(X_test)\n",
    "X_test_tree_fs = preprocessor_tree_fs.transform(X_test)"
   ],
   "id": "a6b603be2f887e3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modellabhängige Datenvorbereitung\n",
    "Ich habe mich entschieden, unterschiedliche Pipelines für verschiedene Modellgruppen zu definieren, um eine effiziente und modellgerechte Datenvorbereitung zu ermöglichen. Zusätzlich habe ich PCA und Feature Selection integriert, um die Dimensionen zu reduzieren und die relevantesten Merkmale für jedes Modell hervorzuheben.\n",
    "\n",
    "- Lineare Regression (Baseline-Modell)\n",
    "    - **Zweck:** Die Lineare Regression dient als Baseline-Modell, um die Modellleistung mit einer einfachen, interpretierten Methode zu vergleichen.\n",
    "    - **Encoding und Skalierung:** Für die Lineare Regression verwende ich One-Hot-Encoding für die kategorischen Variablen (Monat, Wochentag, Quartal, Jahreszeit), um den linearen Zusammenhang zwischen den einzelnen Kategorien und dem Zielwert explizit zu erfassen. Zudem wird ein StandardScaler auf die numerischen Variablen angewendet, da lineare Modelle empfindlich auf unterschiedliche Skalen reagieren.\n",
    "    - **PCA:** Zusätzlich habe ich PCA (Principal Component Analysis) in die Pipeline integriert, um die Anzahl der Merkmale zu reduzieren und so die Berechnungen zu beschleunigen. Die PCA ist besonders hilfreich für die Lineare Regression, da sie das Modell auf die wichtigsten Hauptkomponenten fokussiert, ohne die interpretierbare Varianz zu verlieren. Die Anzahl der Hauptkomponenten wurde so gewählt, dass 95 % der Varianz erhalten bleiben, was eine gute Balance zwischen Komplexitätsreduktion und Informationserhalt bietet.\n",
    "\n",
    "- Random Forest und Gradient Boosting\n",
    "    - **Zweck:** Diese Modelle sind in der Lage, nichtlineare Zusammenhänge und Interaktionen zwischen den Variablen zu erfassen und robust gegen Ausreißer.\n",
    "    - **Encoding und Skalierung:** Da baumbasierte Modelle unempfindlich gegenüber unterschiedlichen Skalen sind, lasse ich die numerischen Variablen unverändert (passthrough). Bei den kategorischen Variablen setze ich One-Hot-Encoding ein, um die Interpretierbarkeit der Features zu erhöhen und Redundanzen in den Baumstrukturen zu vermeiden. Alternativ könnte auch ein Label-Encoding für größere Datensätze verwendet werden, wenn Rechenzeit optimiert werden soll.\n"
   ],
   "id": "dca0c99b7afa6bbb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Speicherung der prozessierten Daten",
   "id": "ecd501737f0e4884"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T15:41:23.637783Z",
     "start_time": "2024-10-29T15:41:23.502655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sicherstellen, dass der Ordner 'data/processed' existiert\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Speichern der Trainings- und Testdaten für lineare Modelle\n",
    "pd.DataFrame(X_train_lr_pca).to_csv('../data/processed/X_train_lr_pca.csv', index=False)\n",
    "pd.DataFrame(X_test_lr_pca).to_csv('../data/processed/X_test_lr_pca.csv', index=False)\n",
    "\n",
    "# Speichern der Trainings- und Testdaten für baumbasierte Modelle\n",
    "pd.DataFrame(X_train_tree_fs).to_csv('../data/processed/X_train_tree_fs.csv', index=False)\n",
    "pd.DataFrame(X_test_tree_fs).to_csv('../data/processed/X_test_tree_fs.csv', index=False)\n",
    "\n",
    "# Zielwerte speichern\n",
    "pd.DataFrame(y_train).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.DataFrame(y_test).to_csv('../data/processed/y_test.csv', index=False)"
   ],
   "id": "8d2b77730cd3120c",
   "outputs": [],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
